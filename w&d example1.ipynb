{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25472\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Categorical base columns.\n",
    "gender = tf.contrib.layers.sparse_column_with_keys(column_name=\"gender\", keys=[\"Female\", \"Male\"])\n",
    "race = tf.contrib.layers.sparse_column_with_keys(column_name=\"race\", keys=[\n",
    "  \"Amer-Indian-Eskimo\", \"Asian-Pac-Islander\", \"Black\", \"Other\", \"White\"])\n",
    "education = tf.contrib.layers.sparse_column_with_hash_bucket(\"education\", hash_bucket_size=1000)\n",
    "marital_status = tf.contrib.layers.sparse_column_with_hash_bucket(\"marital_status\", hash_bucket_size=100)\n",
    "relationship = tf.contrib.layers.sparse_column_with_hash_bucket(\"relationship\", hash_bucket_size=100)\n",
    "workclass = tf.contrib.layers.sparse_column_with_hash_bucket(\"workclass\", hash_bucket_size=100)\n",
    "occupation = tf.contrib.layers.sparse_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "native_country = tf.contrib.layers.sparse_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)\n",
    "\n",
    "# Continuous base columns.\n",
    "age = tf.contrib.layers.real_valued_column(\"age\")\n",
    "age_buckets = tf.contrib.layers.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "education_num = tf.contrib.layers.real_valued_column(\"education_num\")\n",
    "capital_gain = tf.contrib.layers.real_valued_column(\"capital_gain\")\n",
    "capital_loss = tf.contrib.layers.real_valued_column(\"capital_loss\")\n",
    "hours_per_week = tf.contrib.layers.real_valued_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_columns = [\n",
    "  gender, native_country, education, occupation, workclass, marital_status, relationship, age_buckets,\n",
    "  tf.contrib.layers.crossed_column([education, occupation], hash_bucket_size=int(1e4)),\n",
    "  tf.contrib.layers.crossed_column([native_country, occupation], hash_bucket_size=int(1e4)),\n",
    "  tf.contrib.layers.crossed_column([age_buckets, race, occupation], hash_bucket_size=int(1e6))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n"
     ]
    }
   ],
   "source": [
    "deep_columns = [\n",
    "  tf.contrib.layers.embedding_column(workclass, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(education, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(marital_status, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(gender, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(relationship, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(race, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(native_country, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(occupation, dimension=8),\n",
    "  age, education_num, capital_gain, capital_loss, hours_per_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-aaa9ff4251b8>:7: calling DNNLinearCombinedClassifier.__init__ (from tensorflow.contrib.learn.python.learn.estimators.dnn_linear_combined) with fix_global_step_increment_bug=False is deprecated and will be removed after 2017-04-15.\n",
      "Instructions for updating:\n",
      "Please set fix_global_step_increment_bug=True and update training steps in your pipeline. See pydoc for details.\n",
      "WARNING:tensorflow:From C:\\Users\\25472\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn_linear_combined.py:676: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From C:\\Users\\25472\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From C:\\Users\\25472\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:428: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001A16C6B68D0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\25472\\\\AppData\\\\Local\\\\Temp\\\\tmpqhq7vphi'}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "model_dir = tempfile.mkdtemp()\n",
    "m = tf.contrib.learn.DNNLinearCombinedClassifier(\n",
    "    model_dir=model_dir,\n",
    "    linear_feature_columns=wide_columns,\n",
    "    dnn_feature_columns=deep_columns,\n",
    "    dnn_hidden_units=[100, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "# Define the column names for the data sets.\n",
    "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "  \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "  \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]\n",
    "LABEL_COLUMN = 'label'\n",
    "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
    "                       \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
    "CONTINUOUS_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\",\n",
    "                      \"hours_per_week\"]\n",
    "\n",
    "# Download the training and test data to temporary files.\n",
    "# Alternatively, you can download them yourself and change train_file and\n",
    "# test_file to your own paths.\n",
    "train_file = 'train_iris' \n",
    "test_file = 'test_iris'\n",
    "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", train_file)\n",
    "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", test_file)\n",
    "\n",
    "# Read the training and test data sets into Pandas dataframe.\n",
    "df_train = pd.read_csv(train_file, names=COLUMNS, skipinitialspace=True)\n",
    "df_test = pd.read_csv(test_file, names=COLUMNS, skipinitialspace=True, skiprows=1)\n",
    "df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)\n",
    "df_test[LABEL_COLUMN] = (df_test['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "def input_fn(df):\n",
    "  # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "  # the values of that column stored in a constant Tensor.\n",
    "  continuous_cols = {k: tf.constant(df[k].values)\n",
    "                     for k in CONTINUOUS_COLUMNS}\n",
    "  # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "  # to the values of that column stored in a tf.SparseTensor.\n",
    "  categorical_cols = {k: tf.SparseTensor(\n",
    "      indices=[[i, 0] for i in range(df[k].size)],\n",
    "      values=df[k].values,\n",
    "      dense_shape=[df[k].size, 1])\n",
    "                      for k in CATEGORICAL_COLUMNS}\n",
    "  # Merges the two dictionaries into one.\n",
    "  feature_cols = merge_two_dicts(continuous_cols, categorical_cols)\n",
    "  # Converts the label column into a constant Tensor.\n",
    "  label = tf.constant(df[LABEL_COLUMN].values)\n",
    "  # Returns the feature columns and the label.\n",
    "  return feature_cols, label\n",
    "\n",
    "def train_input_fn():\n",
    "  return input_fn(df_train)\n",
    "\n",
    "def eval_input_fn():\n",
    "  return input_fn(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\25472\\AppData\\Local\\Temp\\tmpqhq7vphi\\model.ckpt-202\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 202 into C:\\Users\\25472\\AppData\\Local\\Temp\\tmpqhq7vphi\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6355717, step = 202\n",
      "INFO:tensorflow:global_step/sec: 7.24834\n",
      "INFO:tensorflow:loss = 0.59581727, step = 402 (23.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8434\n",
      "INFO:tensorflow:global_step/sec: 22.5269\n",
      "INFO:tensorflow:loss = 0.41993442, step = 602 (9.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8533\n",
      "INFO:tensorflow:global_step/sec: 22.5172\n",
      "INFO:tensorflow:loss = 0.36740306, step = 802 (8.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3988\n",
      "INFO:tensorflow:global_step/sec: 22.3157\n",
      "INFO:tensorflow:loss = 0.3686035, step = 1002 (8.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4332\n",
      "INFO:tensorflow:global_step/sec: 20.6195\n",
      "INFO:tensorflow:loss = 0.34272543, step = 1202 (9.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0959\n",
      "INFO:tensorflow:global_step/sec: 16.8378\n",
      "INFO:tensorflow:loss = 0.66590613, step = 1402 (11.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.887\n",
      "INFO:tensorflow:global_step/sec: 21.9894\n",
      "INFO:tensorflow:loss = 0.4843966, step = 1602 (9.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7602\n",
      "INFO:tensorflow:global_step/sec: 21.6726\n",
      "INFO:tensorflow:loss = 0.33231497, step = 1802 (9.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6679\n",
      "INFO:tensorflow:global_step/sec: 21.3558\n",
      "INFO:tensorflow:loss = 0.34014606, step = 2002 (9.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4274\n",
      "INFO:tensorflow:global_step/sec: 21.6359\n",
      "INFO:tensorflow:loss = 0.39566213, step = 2202 (9.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6654\n",
      "INFO:tensorflow:global_step/sec: 21.4499\n",
      "INFO:tensorflow:loss = 0.39846343, step = 2402 (9.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1308\n",
      "INFO:tensorflow:global_step/sec: 21.6634\n",
      "INFO:tensorflow:loss = 0.39412025, step = 2602 (9.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7278\n",
      "INFO:tensorflow:global_step/sec: 21.6359\n",
      "INFO:tensorflow:loss = 0.38679156, step = 2802 (9.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1046\n",
      "INFO:tensorflow:global_step/sec: 21.0006\n",
      "INFO:tensorflow:loss = 0.36230746, step = 3002 (9.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2361\n",
      "INFO:tensorflow:global_step/sec: 21.7094\n",
      "INFO:tensorflow:loss = 0.3547751, step = 3202 (9.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5402\n",
      "INFO:tensorflow:global_step/sec: 21.7371\n",
      "INFO:tensorflow:loss = 0.34976298, step = 3402 (9.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3826\n",
      "INFO:tensorflow:global_step/sec: 21.5175\n",
      "INFO:tensorflow:loss = 0.34630445, step = 3602 (9.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3424\n",
      "INFO:tensorflow:global_step/sec: 21.3113\n",
      "INFO:tensorflow:loss = 0.34420756, step = 3802 (9.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6085\n",
      "INFO:tensorflow:global_step/sec: 22.0463\n",
      "INFO:tensorflow:loss = 0.34327823, step = 4002 (9.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3692\n",
      "INFO:tensorflow:global_step/sec: 21.4364\n",
      "INFO:tensorflow:loss = 0.34343144, step = 4202 (9.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8763\n",
      "INFO:tensorflow:global_step/sec: 21.3335\n",
      "INFO:tensorflow:loss = 0.34489006, step = 4402 (9.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7371\n",
      "INFO:tensorflow:global_step/sec: 21.8205\n",
      "INFO:tensorflow:loss = 0.3469019, step = 4602 (9.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7834\n",
      "INFO:tensorflow:global_step/sec: 21.6039\n",
      "INFO:tensorflow:loss = 0.34560397, step = 4802 (9.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6542\n",
      "INFO:tensorflow:global_step/sec: 21.8252\n",
      "INFO:tensorflow:loss = 0.34352794, step = 5002 (9.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.298\n",
      "INFO:tensorflow:global_step/sec: 21.5402\n",
      "INFO:tensorflow:loss = 0.34123617, step = 5202 (9.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3915\n",
      "INFO:tensorflow:loss = 0.33906084, step = 5402 (9.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5902\n",
      "INFO:tensorflow:global_step/sec: 20.657\n",
      "INFO:tensorflow:loss = 0.33702216, step = 5602 (9.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2721\n",
      "INFO:tensorflow:global_step/sec: 21.0265\n",
      "INFO:tensorflow:loss = 0.3350381, step = 5802 (9.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3871\n",
      "INFO:tensorflow:global_step/sec: 21.7602\n",
      "INFO:tensorflow:loss = 0.3331833, step = 6002 (9.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3068\n",
      "INFO:tensorflow:global_step/sec: 20.5409\n",
      "INFO:tensorflow:loss = 0.33144677, step = 6202 (9.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9207\n",
      "INFO:tensorflow:global_step/sec: 21.1877\n",
      "INFO:tensorflow:loss = 0.32984447, step = 6402 (9.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8299\n",
      "INFO:tensorflow:global_step/sec: 21.691\n",
      "INFO:tensorflow:loss = 0.328286, step = 6602 (9.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1701\n",
      "INFO:tensorflow:global_step/sec: 20.9533\n",
      "INFO:tensorflow:loss = 0.32681292, step = 6802 (9.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.396\n",
      "INFO:tensorflow:global_step/sec: 21.4409\n",
      "INFO:tensorflow:loss = 0.32554623, step = 7002 (9.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9188\n",
      "INFO:tensorflow:global_step/sec: 21.9894\n",
      "INFO:tensorflow:loss = 0.32431576, step = 7202 (9.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9894\n",
      "INFO:tensorflow:global_step/sec: 21.4409\n",
      "INFO:tensorflow:loss = 0.30962697, step = 7402 (9.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4382\n",
      "INFO:tensorflow:global_step/sec: 21.6772\n",
      "INFO:tensorflow:loss = 0.30918154, step = 7602 (9.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.5946\n",
      "INFO:tensorflow:global_step/sec: 21.2273\n",
      "INFO:tensorflow:loss = 0.30870733, step = 7802 (9.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4454\n",
      "INFO:tensorflow:global_step/sec: 21.8112\n",
      "INFO:tensorflow:loss = 0.3081972, step = 8002 (9.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5857\n",
      "INFO:tensorflow:global_step/sec: 21.8299\n",
      "INFO:tensorflow:loss = 0.30756396, step = 8202 (9.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2273\n",
      "INFO:tensorflow:global_step/sec: 21.7787\n",
      "INFO:tensorflow:loss = 0.30714023, step = 8402 (9.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9517\n",
      "INFO:tensorflow:global_step/sec: 21.8672\n",
      "INFO:tensorflow:loss = 0.30677673, step = 8602 (9.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7927\n",
      "INFO:tensorflow:global_step/sec: 21.2493\n",
      "INFO:tensorflow:loss = 0.30644983, step = 8802 (9.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0339\n",
      "INFO:tensorflow:global_step/sec: 20.0574\n",
      "INFO:tensorflow:loss = 0.30615193, step = 9002 (9.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5512\n",
      "INFO:tensorflow:global_step/sec: 16.6514\n",
      "INFO:tensorflow:loss = 0.30586216, step = 9202 (11.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8434\n",
      "INFO:tensorflow:global_step/sec: 19.3296\n",
      "INFO:tensorflow:loss = 0.3055831, step = 9402 (10.064 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 19.3406\n",
      "INFO:tensorflow:global_step/sec: 20.216\n",
      "INFO:tensorflow:loss = 0.30532143, step = 9602 (10.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2681\n",
      "INFO:tensorflow:global_step/sec: 20.6195\n",
      "INFO:tensorflow:loss = 0.30507264, step = 9802 (9.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.703\n",
      "INFO:tensorflow:global_step/sec: 21.2891\n",
      "INFO:tensorflow:loss = 0.3048206, step = 10002 (9.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.3024\n",
      "INFO:tensorflow:global_step/sec: 21.5902\n",
      "INFO:tensorflow:loss = 0.30458426, step = 10202 (9.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9894\n",
      "INFO:tensorflow:global_step/sec: 21.9376\n",
      "INFO:tensorflow:loss = 0.3043545, step = 10402 (9.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9376\n",
      "INFO:tensorflow:loss = 0.3041301, step = 10602 (9.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5584\n",
      "INFO:tensorflow:global_step/sec: 20.7872\n",
      "INFO:tensorflow:loss = 0.30391645, step = 10802 (9.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2493\n",
      "INFO:tensorflow:global_step/sec: 21.6268\n",
      "INFO:tensorflow:loss = 0.30370554, step = 11002 (9.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9\n",
      "INFO:tensorflow:global_step/sec: 22.0131\n",
      "INFO:tensorflow:loss = 0.303502, step = 11202 (9.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.4319\n",
      "INFO:tensorflow:global_step/sec: 21.5085\n",
      "INFO:tensorflow:loss = 0.3033127, step = 11402 (9.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8252\n",
      "INFO:tensorflow:global_step/sec: 21.7509\n",
      "INFO:tensorflow:loss = 0.30311626, step = 11602 (9.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6634\n",
      "INFO:tensorflow:global_step/sec: 21.4814\n",
      "INFO:tensorflow:loss = 0.3029302, step = 11802 (9.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1127\n",
      "INFO:tensorflow:global_step/sec: 21.8066\n",
      "INFO:tensorflow:loss = 0.3027626, step = 12002 (9.373 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2fa3c731c751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[0;32m    523\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks)\u001b[0m\n\u001b[0;32m   1093\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1095\u001b[1;33m           \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_fn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1096\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1157\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1238\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1312\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m.fit(input_fn=train_input_fn, steps=20000)\n",
    "results = m.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results):\n",
    "    print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\25472\\AppData\\Local\\Temp\\tmp880ivbik\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\25472\\\\AppData\\\\Local\\\\Temp\\\\tmp880ivbik', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001CB189A7828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\25472\\AppData\\Local\\Temp\\tmp880ivbik\\model.ckpt.\n",
      "INFO:tensorflow:loss = 10429618000.0, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\25472\\AppData\\Local\\Temp\\tmp880ivbik\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10429618000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x1cb14307da0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = pd.DataFrame({'col1': range(3000), 'col2': range(3000), 'label': range(3000)})\n",
    "label = data.pop('label')\n",
    "def input_fn_train():\n",
    "    def input_fn():\n",
    "        dataset = tf.data.Dataset.from_tensors((dict(data), label))\n",
    "        dataset.repeat()\n",
    "        dataset.batch(256)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    return input_fn\n",
    "\n",
    "train_input_f = input_fn_train()\n",
    "\n",
    "feature_columns = [\n",
    "    tf.feature_column.numeric_column(key=\"col1\"),\n",
    "    tf.feature_column.numeric_column(key=\"col2\")\n",
    "]\n",
    "model = tf.estimator.DNNRegressor(hidden_units=[20, 20], feature_columns=feature_columns)\n",
    "model.train(input_fn=train_input_f, steps=20000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.DataFrame({'col1': [1, 2, 3, 4], 'col2': [2, 3, 4, 5], 'label': [0, 1, 2, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  label\n",
       "0     1     2      0\n",
       "1     2     3      1\n",
       "2     3     4      2\n",
       "3     4     5      3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
