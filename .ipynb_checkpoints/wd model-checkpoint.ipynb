{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index(['userid', 'albumid', 'id', 'actor_x', 'area_x', 'channelid_x', 'cpid_x',\n",
    "#        'director_x', 'language_x', 'paytype_x', 'score', 'tag_x', 'year',\n",
    "#        'updatetype', 'actor_y', 'director_y', 'area_y', 'channelid_y',\n",
    "#        'cpid_y', 'tag_y', 'paytype_y', 'language_y', 'score_x', 'score_y',\n",
    "#        'year_x', 'year_y'],\n",
    "#       dtype='object')\n",
    "\n",
    "_FEATURE_LEN = {\n",
    "    'language': 20,\n",
    "    'channelid': 16,\n",
    "    'paytype': 2,\n",
    "    'updatetype': 2,\n",
    "    'cpid': 6,\n",
    "    'area': 187,\n",
    "    'director': 15124,\n",
    "    'actor': 15231,\n",
    "    'tag': 9430\n",
    "}\n",
    "\n",
    "_FEATURE_EMBEDDING_SIZE = {\n",
    "    'language': 2,\n",
    "    'channelid': 2,\n",
    "    'paytype': 2,\n",
    "    'updatetype': 2,\n",
    "    'cpid': 4,\n",
    "    'area': 16,\n",
    "    'director': 32,\n",
    "    'actor': 32,\n",
    "    'tag': 32\n",
    "}\n",
    "\n",
    "\n",
    "updatetype = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'updatetype', range(_FEATURE_LEN['updatetype']))\n",
    "channelid = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'channelid_x', range(_FEATURE_LEN['channelid']))\n",
    "area = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'area_x', range(_FEATURE_LEN['area']))\n",
    "cpid = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'cpid_x', range(_FEATURE_LEN['cpid']))\n",
    "actor = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'actor_x', range(_FEATURE_LEN['actor']))\n",
    "director = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'director_x', range(_FEATURE_LEN['director']))\n",
    "language = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'language_x', range(_FEATURE_LEN['language']))\n",
    "paytype = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'paytype_x', range(_FEATURE_LEN['paytype']))\n",
    "\n",
    "tag = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'tag_x', range(_FEATURE_LEN['tag']))\n",
    "year = tf.feature_column.numeric_column('year')\n",
    "\n",
    "\n",
    "channelid1 = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'channelid_y', range(_FEATURE_LEN['channelid']))\n",
    "area1 = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'area_y', range(_FEATURE_LEN['area']))\n",
    "cpid1 = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'cpid_y', range(_FEATURE_LEN['cpid']))\n",
    "actor1 = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'actor_y', range(_FEATURE_LEN['actor']))\n",
    "director1 = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'director_y', range(_FEATURE_LEN['director']))\n",
    "language1 = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'language_y', range(_FEATURE_LEN['language']))\n",
    "paytype1 = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'paytype_y', range(_FEATURE_LEN['paytype']))\n",
    "\n",
    "tag1 = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            'tag_y', range(_FEATURE_LEN['tag']))\n",
    "\n",
    "score = tf.feature_column.numeric_column('score')\n",
    "score_x = tf.feature_column.numeric_column('score_x')\n",
    "score_y = tf.feature_column.numeric_column('score_y')\n",
    "\n",
    "year = tf.feature_column.numeric_column('year')\n",
    "year_x = tf.feature_column.numeric_column('year_x')\n",
    "year_y = tf.feature_column.numeric_column('year_y')\n",
    "\n",
    "\n",
    "deep_columns = [    \n",
    "    score,\n",
    "    score_x,\n",
    "    score_y,\n",
    "    year,\n",
    "    year_x,\n",
    "    year_y\n",
    "]\n",
    "\n",
    "emb_columns = [\n",
    "    tf.feature_column.shared_embedding_columns\n",
    "        ([channelid, channelid1], dimension=_FEATURE_EMBEDDING_SIZE['channelid']),\n",
    "    tf.feature_column.shared_embedding_columns\n",
    "        ([area, area1], dimension=_FEATURE_EMBEDDING_SIZE['area']),\n",
    "    tf.feature_column.shared_embedding_columns\n",
    "        ([cpid, cpid1], dimension=_FEATURE_EMBEDDING_SIZE['cpid']),\n",
    "    tf.feature_column.shared_embedding_columns\n",
    "        ([actor, actor1], dimension=_FEATURE_EMBEDDING_SIZE['actor']),\n",
    "    tf.feature_column.shared_embedding_columns\n",
    "        ([director, director1], dimension=_FEATURE_EMBEDDING_SIZE['director']),\n",
    "    tf.feature_column.shared_embedding_columns\n",
    "        ([language, language1], dimension=_FEATURE_EMBEDDING_SIZE['language']),\n",
    "    tf.feature_column.shared_embedding_columns\n",
    "        ([paytype, paytype1], dimension=_FEATURE_EMBEDDING_SIZE['paytype']),\n",
    "    tf.feature_column.shared_embedding_columns\n",
    "        ([tag, tag1], dimension=_FEATURE_EMBEDDING_SIZE['tag'])\n",
    "]\n",
    "\n",
    "for col in emb_columns:\n",
    "    deep_columns.extend(col)\n",
    "\n",
    "\n",
    "base_columns = [\n",
    "    channelid,\n",
    "    area,\n",
    "    cpid,\n",
    "    actor,\n",
    "    director,\n",
    "    language,\n",
    "    paytype,\n",
    "    channelid1,\n",
    "    area1,\n",
    "    cpid1,\n",
    "    actor1,\n",
    "    director1,\n",
    "    language1,\n",
    "    paytype1,\n",
    "]\n",
    "\n",
    "_HASH_BUCKET_SIZE = 1024\n",
    "\n",
    "cross_columns = [\n",
    "    tf.feature_column.crossed_column(\n",
    "    ['actor_x', 'actor_y'], hash_bucket_size=_HASH_BUCKET_SIZE),\n",
    "    tf.feature_column.crossed_column(\n",
    "    ['director_x', 'director_y'], hash_bucket_size=_HASH_BUCKET_SIZE),\n",
    "    tf.feature_column.crossed_column(\n",
    "    ['cpid_x', 'cpid_y'], hash_bucket_size=_HASH_BUCKET_SIZE),\n",
    "    tf.feature_column.crossed_column(\n",
    "    ['tag_x', 'tag_y'], hash_bucket_size=_HASH_BUCKET_SIZE)\n",
    "]\n",
    "\n",
    "wide_columns = base_columns + cross_columns \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_json('train_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index(['userid', 'albumid', 'id', 'actor_x', 'area_x', 'channelid_x', 'cpid_x',\n",
    "#        'director_x', 'language_x', 'paytype_x', 'score', 'tag_x', 'year',\n",
    "#        'updatetype', 'actor_y', 'director_y', 'area_y', 'channelid_y',\n",
    "#        'cpid_y', 'tag_y', 'paytype_y', 'language_y', 'score_x', 'score_y',\n",
    "#        'year_x', 'year_y'],\n",
    "#       dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_FEATURE_COLUMNS = {'actor_x', 'area_x', 'channelid_x', 'cpid_x', \n",
    "                         'director_x', 'language_x', 'paytype_x', 'tag_x', 'year',\n",
    "                         'updatetype', 'actor_y', 'director_y', 'area_y', 'channelid_y',\n",
    "                         'cpid_y', 'tag_y', 'paytype_y', 'language_y'}\n",
    "VALUE_FEATURE_COLUMNS = {'score', 'year', 'score_x', 'score_y','year_x', 'year_y', 'label'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates()\n",
    "train_data = train_data.head(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "director_y + 598\n",
      "actor_x + 20\n",
      "area_x + 2\n",
      "tag_y + 1170\n",
      "tag_x + 13\n",
      "cpid_x + 1\n",
      "cpid_y + 598\n",
      "channelid_x + 1\n",
      "language_x + 1\n",
      "director_x + 2\n",
      "paytype_x + 1\n",
      "year + 1\n",
      "actor_y + 598\n",
      "channelid_y + 598\n",
      "area_y + 598\n",
      "paytype_y + 598\n",
      "updatetype + 1\n",
      "language_y + 598\n"
     ]
    }
   ],
   "source": [
    "for key in MULTI_FEATURE_COLUMNS:\n",
    "    l = [str(v).split(',') for v in train_data[key].tolist()]\n",
    "    l = [[int(v) for v in vv] for vv in l]\n",
    "    maxl = max([len(word) for word in l])\n",
    "    print('{} + {}'.format(key, maxl))\n",
    "    for v in l:\n",
    "        while len(v) < maxl:\n",
    "            v.append(-1)\n",
    "    data_dict[key] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in VALUE_FEATURE_COLUMNS:\n",
    "    data_dict[key] = train_data[key].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './modeldir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "  value: 1\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001AC1464C080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "hidden_units = [16, 20]\n",
    "\n",
    "  # Create a tf.estimator.RunConfig to ensure the model is run on CPU, which\n",
    "  # trains faster than GPU for this model.\n",
    "run_config = tf.estimator.RunConfig().replace(\n",
    "  session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "model_dir = './modeldir'\n",
    "\n",
    "\n",
    "model = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir=model_dir,\n",
    "    n_classes=2,\n",
    "    linear_feature_columns=wide_columns,\n",
    "    dnn_feature_columns=deep_columns,\n",
    "    dnn_hidden_units=hidden_units,\n",
    "    config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = len(data_dict['actor_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = 18465\n",
    "label = [1 for _ in range(3000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensors((data_dict, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_train():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data_dict, label))\n",
    "    dataset = dataset.batch(30).repeat()\n",
    "    print(dataset)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ({director_y: (?, 598), actor_x: (?, 20), area_x: (?, 2), tag_y: (?, 1170), tag_x: (?, 13), cpid_x: (?, 1), cpid_y: (?, 598), channelid_x: (?, 1), language_x: (?, 1), director_x: (?, 2), paytype_x: (?, 1), year: (?,), actor_y: (?, 598), channelid_y: (?, 598), area_y: (?, 598), paytype_y: (?, 598), updatetype: (?, 1), language_y: (?, 598), year_y: (?,), year_x: (?,), score_y: (?,), score: (?,), score_x: (?,), label: (?,)}, (?,)), types: ({director_y: tf.int32, actor_x: tf.int32, area_x: tf.int32, tag_y: tf.int32, tag_x: tf.int32, cpid_x: tf.int32, cpid_y: tf.int32, channelid_x: tf.int32, language_x: tf.int32, director_x: tf.int32, paytype_x: tf.int32, year: tf.int32, actor_y: tf.int32, channelid_y: tf.int32, area_y: tf.int32, paytype_y: tf.int32, updatetype: tf.int32, language_y: tf.int32, year_y: tf.int32, year_x: tf.float32, score_y: tf.float32, score: tf.int32, score_x: tf.float32, label: tf.int32}, tf.int32)>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./modeldir\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.69276\n",
      "INFO:tensorflow:loss = 0.0, step = 100 (37.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.40063\n",
      "INFO:tensorflow:loss = 0.0, step = 200 (29.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.46958\n",
      "INFO:tensorflow:loss = 0.0, step = 300 (28.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.45037\n",
      "INFO:tensorflow:loss = 0.0, step = 400 (29.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.18358\n",
      "INFO:tensorflow:loss = 0.0, step = 500 (31.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.41325\n",
      "INFO:tensorflow:loss = 0.0, step = 600 (29.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.37442\n",
      "INFO:tensorflow:loss = 0.0, step = 700 (29.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.32795\n",
      "INFO:tensorflow:loss = 0.0, step = 800 (30.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.29474\n",
      "INFO:tensorflow:loss = 0.0, step = 900 (30.299 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-32fe4802b658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1205\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1471\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1472\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1157\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1238\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1312\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "model.train(input_fn=input_fn_train, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensors({'key': [[1], [2]], 'value': [[2], [3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: {key: (2, 1), value: (2, 1)}, types: {key: tf.int32, value: tf.int32}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.repeat(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: {key: (?, 2, 1), value: (?, 2, 1)}, types: {key: tf.int32, value: tf.int32}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Updatetype</th>\n",
       "      <th>actor</th>\n",
       "      <th>albumname</th>\n",
       "      <th>area</th>\n",
       "      <th>channelid</th>\n",
       "      <th>cpid</th>\n",
       "      <th>director</th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>paytype</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9850</td>\n",
       "      <td>庆元明代银矿探秘</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>02|3294913</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7676</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9850</td>\n",
       "      <td>习近平就俄罗斯军机坠毁事件向普京致慰问电</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>02|3164963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>647,8875</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9850</td>\n",
       "      <td>走一线看经济 大有可为的甜蜜事业</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>02|3561132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9850</td>\n",
       "      <td>壹起去旅行</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>02|12271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5891,7379</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9850</td>\n",
       "      <td>德云社：桃花女破周公（郭德纲）</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4128</td>\n",
       "      <td>02|966626</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8976</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Updatetype actor             albumname area  channelid  cpid director  \\\n",
       "0           0  9850              庆元明代银矿探秘   65          0     0     9675   \n",
       "1           0  9850  习近平就俄罗斯军机坠毁事件向普京致慰问电   65          1     0     9675   \n",
       "2           0  9850      走一线看经济 大有可为的甜蜜事业   65          1     0     9675   \n",
       "3           0  9850                 壹起去旅行   65          1     0     9675   \n",
       "4           0  9850       德云社：桃花女破周公（郭德纲）   65          1     0     4128   \n",
       "\n",
       "           id  language  paytype score        tag  year  \n",
       "0  02|3294913         0        0   7.6       7676  2017  \n",
       "1  02|3164963         0        0   8.2   647,8875  2016  \n",
       "2  02|3561132         0        0   8.0          0  2018  \n",
       "3    02|12271         1        0   8.0  5891,7379  2016  \n",
       "4   02|966626         2        0   6.1       8976  2013  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('/Users/qianjay/video_parsed.dat')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[['id', 'actor', 'Updatetype', 'area', 'channelid', 'cpid', 'director', 'language', 'paytype', 'score', 'tag', 'year']]\n",
    "data['updatetype'] = data['Updatetype']\n",
    "data = data.drop(['Updatetype'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actor</th>\n",
       "      <th>area</th>\n",
       "      <th>channelid</th>\n",
       "      <th>cpid</th>\n",
       "      <th>director</th>\n",
       "      <th>language</th>\n",
       "      <th>paytype</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "      <th>year</th>\n",
       "      <th>updatetype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02|3294913</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7676</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02|3164963</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>647,8875</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02|3561132</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02|12271</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5891,7379</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02|966626</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8976</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id actor area  channelid  cpid director  language  paytype score  \\\n",
       "0  02|3294913  9850   65          0     0     9675         0        0   7.6   \n",
       "1  02|3164963  9850   65          1     0     9675         0        0   8.2   \n",
       "2  02|3561132  9850   65          1     0     9675         0        0   8.0   \n",
       "3    02|12271  9850   65          1     0     9675         1        0   8.0   \n",
       "4   02|966626  9850   65          1     0     4128         2        0   6.1   \n",
       "\n",
       "         tag  year  updatetype  \n",
       "0       7676  2017           0  \n",
       "1   647,8875  2016           0  \n",
       "2          0  2018           0  \n",
       "3  5891,7379  2016           0  \n",
       "4       8976  2013           0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SINGLE_FEATURE_COLUMN = {'channelid', 'cpid', 'language', 'paytype'}\n",
    "data_dict = {}\n",
    "for key in SINGLE_FEATURE_COLUMN:\n",
    "    l = [[v] for v in data[key].tolist()]\n",
    "    data_dict[key] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensors(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorDataset shapes: {paytype: (171962, 1), language: (171962, 1), cpid: (171962, 1), channelid: (171962, 1)}, types: {paytype: tf.int32, language: tf.int32, cpid: tf.int32, channelid: tf.int32}>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "63\n",
      "8\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "MULTI_FEATURE_COLUMNS = {'actor', 'area', 'director', 'tag'}\n",
    "for key in MULTI_FEATURE_COLUMNS:\n",
    "    l = [str(v).split(',') for v in data[key].tolist()]\n",
    "    l = [[int(v) for v in vv] for vv in l]\n",
    "    maxl = max([len(word) for word in l])\n",
    "    print(maxl)\n",
    "    for v in l:\n",
    "        while len(v) < maxl:\n",
    "            v.append(-1)\n",
    "    data_dict[key] = l\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paytype', 'language', 'cpid', 'channelid', 'actor', 'director', 'area', 'tag'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensors(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorDataset shapes: {paytype: (171962, 1), language: (171962, 1), cpid: (171962, 1), channelid: (171962, 1), actor: (171962, 54), director: (171962, 63), area: (171962, 8), tag: (171962, 23)}, types: {paytype: tf.int32, language: tf.int32, cpid: tf.int32, channelid: tf.int32, actor: tf.int32, director: tf.int32, area: tf.int32, tag: tf.int32}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actor</th>\n",
       "      <th>area</th>\n",
       "      <th>channelid</th>\n",
       "      <th>cpid</th>\n",
       "      <th>director</th>\n",
       "      <th>language</th>\n",
       "      <th>paytype</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "      <th>year</th>\n",
       "      <th>updatetype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02|3294913</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7676</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02|3164963</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>647,8875</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02|3561132</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02|12271</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5891,7379</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02|966626</td>\n",
       "      <td>9850</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8976</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id actor area  channelid  cpid director  language  paytype score  \\\n",
       "0  02|3294913  9850   65          0     0     9675         0        0   7.6   \n",
       "1  02|3164963  9850   65          1     0     9675         0        0   8.2   \n",
       "2  02|3561132  9850   65          1     0     9675         0        0   8.0   \n",
       "3    02|12271  9850   65          1     0     9675         1        0   8.0   \n",
       "4   02|966626  9850   65          1     0     4128         2        0   6.1   \n",
       "\n",
       "         tag  year  updatetype  \n",
       "0       7676  2017           0  \n",
       "1   647,8875  2016           0  \n",
       "2          0  2018           0  \n",
       "3  5891,7379  2016           0  \n",
       "4       8976  2013           0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9940,6485,4376,1209,14021,8288,13115,9043,6068,6717,1899,5097,12724,8364,3038,895,383,9632,14989,5135,4738,4601,13202,2021,13121,5084,6393,2396,2793,5392,2372,12470,9154,4031,865,12190,7232,9569,3144,14654,13306,9136,9905,1003,6204,974,9887,9581,559,9300,3814,12608,10994,4992\n"
     ]
    }
   ],
   "source": [
    "[len(str(v).split(',')) for v in data['actor']]\n",
    "\n",
    "for v in data['actor']:\n",
    "    if len(str(v).split(',')) == 54:\n",
    "        print(v)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
